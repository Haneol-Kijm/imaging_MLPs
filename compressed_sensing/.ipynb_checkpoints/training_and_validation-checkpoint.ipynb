{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# fastmri\n",
    "import fastmri\n",
    "from fastmri.data import subsample\n",
    "from fastmri.data import transforms, mri_data\n",
    "from fastmri.evaluate import ssim, psnr, nmse\n",
    "from fastmri.losses import SSIMLoss\n",
    "\n",
    "# other stuff\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm \n",
    "from networks import VisionTransformer, ReconNet, Img2Img_Mixer, Unet\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# Device\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastMRIDataset(Dataset):\n",
    "    def __init__(self, isval=False):\n",
    "        self.isval = isval\n",
    "        if not isval:\n",
    "            self.data_path = '/media/hdd1/fastMRIdata/knee/singlecoil_train/' # Adjust training data path here\n",
    "        else:\n",
    "            self.data_path = '/media/hdd1/fastMRIdata/knee/singlecoil_val/' # Adjust validation data path here\n",
    "\n",
    "        self.data = mri_data.SliceDataset(\n",
    "            root=self.data_path,\n",
    "            transform=self.data_transform,\n",
    "            challenge='singlecoil',\n",
    "            use_dataset_cache=True,\n",
    "            )\n",
    "\n",
    "        self.mask_func = subsample.RandomMaskFunc(\n",
    "            center_fractions=[0.08],\n",
    "            accelerations=[4],\n",
    "            )\n",
    "            \n",
    "    def data_transform(self, kspace, mask, target, data_attributes, filename, slice_num):\n",
    "        if self.isval:\n",
    "            seed = tuple(map(ord, filename))\n",
    "        else:\n",
    "            seed = None     \n",
    "        kspace = transforms.to_tensor(kspace)\n",
    "        masked_kspace, _ = transforms.apply_mask(kspace, self.mask_func, seed)        \n",
    "        \n",
    "        target = transforms.to_tensor(target)\n",
    "        zero_fill = fastmri.ifft2c(masked_kspace)\n",
    "        zero_fill = transforms.complex_center_crop(zero_fill, target.shape)   \n",
    "        x = fastmri.complex_abs(zero_fill)\n",
    " \n",
    "        x = x.unsqueeze(0)\n",
    "        target = target.unsqueeze(0)\n",
    "\n",
    "        return (x, target, data_attributes['max'])\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = fastMRIDataset(isval=False)\n",
    "val_dataset = fastMRIDataset(isval=True)\n",
    "\n",
    "ntrain = len(dataset) # Vary training data size here\n",
    "train_dataset, _ = torch.utils.data.random_split(dataset, [ntrain, len(dataset)-ntrain], generator=torch.Generator().manual_seed(42))\n",
    "print(len(train_dataset))\n",
    "\n",
    "batch_size = 1\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, generator=torch.Generator().manual_seed(42))\n",
    "valloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece20988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Init Model\"\"\"\n",
    "# Image to Image Mixer\n",
    "net = Img2Img_Mixer(\n",
    "    img_size = 320,\n",
    "    img_channels = 1,\n",
    "    patch_size = 4,\n",
    "    embed_dim = 128,\n",
    "    num_layers= 16,\n",
    "    f_hidden = 8,\n",
    "    )   \n",
    "        \n",
    "# # Vision Transformer\n",
    "# net = VisionTransformer(\n",
    "#     avrg_img_size=320, \n",
    "#     patch_size=10, \n",
    "#     in_chans=1, embed_dim=44, \n",
    "#     depth=4, num_heads=9, mlp_ratio=4., \n",
    "#     )\n",
    "\n",
    "# # Unet\n",
    "# net = Unet(\n",
    "#     in_chans=1,\n",
    "#     out_chans=1,\n",
    "#     chans=32,\n",
    "#     num_pool_layers=4,\n",
    "#     )\n",
    "\n",
    "model = ReconNet(net).to(device)\n",
    "\n",
    "print('#Params:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33864e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate model\n",
    "def validate(model):\n",
    "    valloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)   \n",
    "    model.eval()    \n",
    "    ssim_ = myutils.SSIM().to(device)\n",
    "    psnr_ = myutils.PSNR().to(device)\n",
    "    psnrs = []\n",
    "    ssims = []\n",
    "    \n",
    "    with tqdm(total=len(valloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, targets, maxval = data        \n",
    "                outputs = model(inputs.to(device))\n",
    "                ssims.append(ssim_(outputs, targets.to(device), maxval.to(device)))\n",
    "                psnrs.append(psnr_(outputs, targets.to(device), maxval.to(device)))\n",
    "                pbar.update(1)\n",
    "    \n",
    "    ssimval = torch.cat(ssims).mean()\n",
    "    \n",
    "    print(' Recon. PSNR: {:0.3f} pm {:0.2f}'.format(torch.cat(psnrs).mean(), 2*torch.cat(psnrs).std()))\n",
    "    print(' Recon. SSIM: {:0.4f} pm {:0.3f}'.format(torch.cat(ssims).mean(), 2*torch.cat(ssims).std()))\n",
    "                \n",
    "    return (1-ssimval).item()\n",
    "\n",
    "# Save model\n",
    "def save_model(path, model, train_hist, val_hist, optimizer, scheduler=None):\n",
    "    net = model.net\n",
    "    if scheduler:\n",
    "        checkpoint = {\n",
    "            'model' :  ReconNet(net),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(), \n",
    "        }\n",
    "    else:\n",
    "        checkpoint = {\n",
    "            'model' :  ReconNet(net),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "    torch.save(train_hist, path + 'train_hist.pt')\n",
    "    torch.save(val_hist, path + 'val_hist.pt')    \n",
    "    torch.save(checkpoint,  path + 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab942405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Choose optimizer\"\"\"\n",
    "criterion = SSIMLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0)\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "best_val = float(\"inf\")\n",
    "path = './' # Path for saving model checkpoint and loss history\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0005,\n",
    "                                          total_steps=40, pct_start=0.1,\n",
    "                                          anneal_strategy='linear',\n",
    "                                          cycle_momentum=False,\n",
    "                                          base_momentum=0., max_momentum=0., div_factor=0.1*40, final_div_factor=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train Model\"\"\"\n",
    "for epoch in tqdm(range(0, 40)): # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    with tqdm(total=len(trainloader)) as pbar:\n",
    "        for data in trainloader:\n",
    "            inputs, targets, maxval = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, targets.to(device), maxval.to(device))\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1, norm_type=1.)\n",
    "            optimizer.step()\n",
    "            pbar.update(1)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    train_hist.append(train_loss/len(trainloader))\n",
    "    print('Epoch {}, Train loss.: {:0.4f}'.format(epoch+1, train_hist[-1]))\n",
    "    \n",
    "    if (epoch+1)%5==0:\n",
    "        val_hist.append(validate(model))        \n",
    "        if val_hist[-1] < best_val:\n",
    "            save_model(path, model, train_hist, val_hist, optimizer, scheduler=scheduler)\n",
    "            best_val = val_hist[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
