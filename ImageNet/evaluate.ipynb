{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8bc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479af97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "from networks import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "PSNR= peak_signal_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################Enter device and the model you wish to test##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fd1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'\n",
    "\n",
    "model_name = \"Img2Img_Mixer\" #Enter same name used when training\n",
    "\n",
    "model = Img2Img_Mixer(\n",
    "        \n",
    "        img_size = 256,   #Image Size (assumed to be square image), here 256 x 256\n",
    "        img_channels = 3, #Image Channels, 3 for RGB, 1 for greyscale\n",
    "        patch_size = 4,   #Patch Size, P\n",
    "        embed_dim = 128,  #Embedding Dimension, C\n",
    "        num_layers = 16,  #Number of Mixer Layers, N\n",
    "        f_hidden = 4,     #Multiplication Factor for Hidden Dimensions, f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aca4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b67f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load paths \n",
    "clean_val= data_path + 'clean_val/'\n",
    "noisy_val= data_path + 'noisy_val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prepare data\n",
    "class data():\n",
    "    \n",
    "    def __init__(self, path_clean, path_noisy):\n",
    "        self.path_clean = path_clean\n",
    "        self.path_noisy = path_noisy\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.path_clean))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data= dict()\n",
    "        data['clean']= torch.load(self.path_clean + '{0:05}'.format(idx))\n",
    "        data['noisy']= torch.load(self.path_noisy + '{0:05}'.format(idx))\n",
    "\n",
    "        return data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entire validation set\n",
    "val_set=data(clean_val, noisy_val)\n",
    "\n",
    "#Dataloader\n",
    "val_dl = DataLoader(val_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b63c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "best_path = models_path +'best_' + model_name + '.pth'     ##path to trained model\n",
    "checkpoint = torch.load(best_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct function\n",
    "def denoise(model, sample): \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "\n",
    "        noisy = sample['noisy'].to(device)\n",
    "        \n",
    "        #################### get the prediction ##############################\n",
    "       \n",
    "        pred = model(noisy)\n",
    "        img = torch.clamp(noisy-pred, 0, 1)                \n",
    "        \n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf22f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSNR of denoised images\n",
    "\n",
    "psnr=0\n",
    "\n",
    "with tqdm(total=len(val_dl)) as pbar:\n",
    "    for sample in val_dl: \n",
    "        pred=denoise(model,sample).detach().cpu().squeeze(0).numpy()\n",
    "        original=sample['clean'].squeeze(0).numpy()\n",
    "        psnr+= PSNR(pred,original)\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"PSNR of the denoised images is: \",psnr/len(val_dl))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8d281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSNR of noisy images\n",
    "\n",
    "psnr=0\n",
    "\n",
    "with tqdm(total=len(val_dl)) as pbar:\n",
    "    for sample in val_dl: \n",
    "        pred= sample['noisy'].squeeze(0).numpy()\n",
    "        original=sample['clean'].squeeze(0).numpy()\n",
    "        psnr+= PSNR(pred,original)\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"PSNR of the nosiy images is: \",psnr/len(val_dl))            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
